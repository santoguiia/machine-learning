{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando a taxa de aprendizagem é muito alta, o algoritmo de descida de gradiente pode divergir, resultando em oscilações ou até mesmo em não convergência para os parâmetros ótimos. Por outro lado, quando a taxa de aprendizagem é muito baixa, o algoritmo pode levar mais tempo para convergir para os parâmetros ótimos ou pode ficar preso em mínimos locais.\n",
    "\n",
    "Vamos experimentar com valores altos e baixos para a taxa de aprendizagem e observar o comportamento do treinamento:\n",
    "\n",
    "1. **Taxa de Aprendizagem Alta**: Vamos definir uma taxa de aprendizagem alta, por exemplo, 1.0.\n",
    "2. **Taxa de Aprendizagem Baixa**: Vamos definir uma taxa de aprendizagem baixa, por exemplo, 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Experimento com taxa de aprendizagem alta (1.0)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m alpha_high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m theta_high \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Reinicializar os parâmetros\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cost_history_high \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Experimento com taxa de aprendizagem alta (1.0)\n",
    "alpha_high = 1.0\n",
    "theta_high = np.random.randn(2)  # Reinicializar os parâmetros\n",
    "\n",
    "cost_history_high = []\n",
    "for k in range(epochs):\n",
    "    theta_high -= alpha_high * gradient(theta_high, np.c_[np.ones(xs.shape), xs], ys)\n",
    "    cost_history_high.append(J(theta_high, np.c_[np.ones(xs.shape), xs], ys))\n",
    "\n",
    "# Experimento com taxa de aprendizagem baixa (0.0001)\n",
    "alpha_low = 0.0001\n",
    "theta_low = np.random.randn(2)  # Reinicializar os parâmetros\n",
    "\n",
    "cost_history_low = []\n",
    "for k in range(epochs):\n",
    "    theta_low -= alpha_low * gradient(theta_low, np.c_[np.ones(xs.shape), xs], ys)\n",
    "    cost_history_low.append(J(theta_low, np.c_[np.ones(xs.shape), xs], ys))\n",
    "\n",
    "# Plotar função de custo ao longo das épocas para ambas as taxas de aprendizagem\n",
    "plt.plot(cost_history_high, label='Alta Taxa de Aprendizagem (1.0)')\n",
    "plt.plot(cost_history_low, label='Baixa Taxa de Aprendizagem (0.0001)')\n",
    "plt.title('Função de custo ao longo das épocas para diferentes taxas de aprendizagem')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Custo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar os resultados:\n",
    "\n",
    "- Para a taxa de aprendizagem alta, a função de custo oscila consideravelmente e pode não convergir para um valor mínimo.\n",
    "- Para a taxa de aprendizagem baixa, a função de custo diminui gradualmente, mas o treinamento pode ser lento e pode demorar mais para convergir.\n",
    "\n",
    "Comparativamente, esses comportamentos são semelhantes aos observados na regressão linear. No entanto, como a regressão logística é uma função sigmoide e a função de custo é não convexa, os efeitos de taxas de aprendizado muito altas podem ser mais pronunciados, resultando em divergência mais rápida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
